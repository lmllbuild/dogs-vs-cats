{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception上的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "读取训练和测试图片，格式化成（299,299,3）的格式。并且划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "n = 24962\n",
    "X = np.zeros((n, 299, 299, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, 1), dtype=np.uint8)\n",
    "\n",
    "train_cat2 = os.listdir(\"train2/cat\")\n",
    "train_dog2 = os.listdir(\"train2/dog\")\n",
    "\n",
    "i = 0\n",
    "for filename in train_cat2:\n",
    "    X[i] = cv2.resize(cv2.imread('train/%s' % filename), (299, 299))\n",
    "    y[i] = 0\n",
    "    i += 1\n",
    "for filename in train_dog2:\n",
    "    X[i] = cv2.resize(cv2.imread('train/%s' % filename), (299, 299))\n",
    "    y[i] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 12500\n",
    "X_test = np.zeros((m, 299, 299, 3), dtype=np.uint8)\n",
    "\n",
    "test_file = os.listdir(\"test\")\n",
    "j = 0\n",
    "for filename in test_file:\n",
    "    X_test[j] = cv2.resize(cv2.imread('test/%s' % filename), (299, 299))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 24962\n",
      "X_test size: (12500, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"i=\", i)\n",
    "print(\"X_test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型一\n",
    "去除顶层，锁定其他所有层，不参与训练；在这模型的基础上，加上GAP层和Dropout层，加sigmoid激活函数得出二分类的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(input_tensor=Lambda(inception_v3.preprocess_input)(Input((299, 299, 3))), weights='imagenet', include_top=False)\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19969 samples, validate on 4993 samples\n",
      "Epoch 1/5\n",
      "19969/19969 [==============================] - 83s 4ms/step - loss: 0.1943 - acc: 0.9282 - val_loss: 0.0355 - val_acc: 0.9920\n",
      "Epoch 2/5\n",
      "19969/19969 [==============================] - 78s 4ms/step - loss: 0.1171 - acc: 0.9578 - val_loss: 0.1437 - val_acc: 0.9465\n",
      "Epoch 3/5\n",
      "19969/19969 [==============================] - 78s 4ms/step - loss: 0.1132 - acc: 0.9579 - val_loss: 0.0684 - val_acc: 0.9784\n",
      "Epoch 4/5\n",
      "19969/19969 [==============================] - 78s 4ms/step - loss: 0.1072 - acc: 0.9603 - val_loss: 0.0985 - val_acc: 0.9666\n",
      "Epoch 5/5\n",
      "19969/19969 [==============================] - 78s 4ms/step - loss: 0.1099 - acc: 0.9588 - val_loss: 0.0325 - val_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bf3e00b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 lambda_1\n",
      "2 conv2d_1\n",
      "3 batch_normalization_1\n",
      "4 activation_1\n",
      "5 conv2d_2\n",
      "6 batch_normalization_2\n",
      "7 activation_2\n",
      "8 conv2d_3\n",
      "9 batch_normalization_3\n",
      "10 activation_3\n",
      "11 max_pooling2d_1\n",
      "12 conv2d_4\n",
      "13 batch_normalization_4\n",
      "14 activation_4\n",
      "15 conv2d_5\n",
      "16 batch_normalization_5\n",
      "17 activation_5\n",
      "18 max_pooling2d_2\n",
      "19 conv2d_9\n",
      "20 batch_normalization_9\n",
      "21 activation_9\n",
      "22 conv2d_7\n",
      "23 conv2d_10\n",
      "24 batch_normalization_7\n",
      "25 batch_normalization_10\n",
      "26 activation_7\n",
      "27 activation_10\n",
      "28 average_pooling2d_1\n",
      "29 conv2d_6\n",
      "30 conv2d_8\n",
      "31 conv2d_11\n",
      "32 conv2d_12\n",
      "33 batch_normalization_6\n",
      "34 batch_normalization_8\n",
      "35 batch_normalization_11\n",
      "36 batch_normalization_12\n",
      "37 activation_6\n",
      "38 activation_8\n",
      "39 activation_11\n",
      "40 activation_12\n",
      "41 mixed0\n",
      "42 conv2d_16\n",
      "43 batch_normalization_16\n",
      "44 activation_16\n",
      "45 conv2d_14\n",
      "46 conv2d_17\n",
      "47 batch_normalization_14\n",
      "48 batch_normalization_17\n",
      "49 activation_14\n",
      "50 activation_17\n",
      "51 average_pooling2d_2\n",
      "52 conv2d_13\n",
      "53 conv2d_15\n",
      "54 conv2d_18\n",
      "55 conv2d_19\n",
      "56 batch_normalization_13\n",
      "57 batch_normalization_15\n",
      "58 batch_normalization_18\n",
      "59 batch_normalization_19\n",
      "60 activation_13\n",
      "61 activation_15\n",
      "62 activation_18\n",
      "63 activation_19\n",
      "64 mixed1\n",
      "65 conv2d_23\n",
      "66 batch_normalization_23\n",
      "67 activation_23\n",
      "68 conv2d_21\n",
      "69 conv2d_24\n",
      "70 batch_normalization_21\n",
      "71 batch_normalization_24\n",
      "72 activation_21\n",
      "73 activation_24\n",
      "74 average_pooling2d_3\n",
      "75 conv2d_20\n",
      "76 conv2d_22\n",
      "77 conv2d_25\n",
      "78 conv2d_26\n",
      "79 batch_normalization_20\n",
      "80 batch_normalization_22\n",
      "81 batch_normalization_25\n",
      "82 batch_normalization_26\n",
      "83 activation_20\n",
      "84 activation_22\n",
      "85 activation_25\n",
      "86 activation_26\n",
      "87 mixed2\n",
      "88 conv2d_28\n",
      "89 batch_normalization_28\n",
      "90 activation_28\n",
      "91 conv2d_29\n",
      "92 batch_normalization_29\n",
      "93 activation_29\n",
      "94 conv2d_27\n",
      "95 conv2d_30\n",
      "96 batch_normalization_27\n",
      "97 batch_normalization_30\n",
      "98 activation_27\n",
      "99 activation_30\n",
      "100 max_pooling2d_3\n",
      "101 mixed3\n",
      "102 conv2d_35\n",
      "103 batch_normalization_35\n",
      "104 activation_35\n",
      "105 conv2d_36\n",
      "106 batch_normalization_36\n",
      "107 activation_36\n",
      "108 conv2d_32\n",
      "109 conv2d_37\n",
      "110 batch_normalization_32\n",
      "111 batch_normalization_37\n",
      "112 activation_32\n",
      "113 activation_37\n",
      "114 conv2d_33\n",
      "115 conv2d_38\n",
      "116 batch_normalization_33\n",
      "117 batch_normalization_38\n",
      "118 activation_33\n",
      "119 activation_38\n",
      "120 average_pooling2d_4\n",
      "121 conv2d_31\n",
      "122 conv2d_34\n",
      "123 conv2d_39\n",
      "124 conv2d_40\n",
      "125 batch_normalization_31\n",
      "126 batch_normalization_34\n",
      "127 batch_normalization_39\n",
      "128 batch_normalization_40\n",
      "129 activation_31\n",
      "130 activation_34\n",
      "131 activation_39\n",
      "132 activation_40\n",
      "133 mixed4\n",
      "134 conv2d_45\n",
      "135 batch_normalization_45\n",
      "136 activation_45\n",
      "137 conv2d_46\n",
      "138 batch_normalization_46\n",
      "139 activation_46\n",
      "140 conv2d_42\n",
      "141 conv2d_47\n",
      "142 batch_normalization_42\n",
      "143 batch_normalization_47\n",
      "144 activation_42\n",
      "145 activation_47\n",
      "146 conv2d_43\n",
      "147 conv2d_48\n",
      "148 batch_normalization_43\n",
      "149 batch_normalization_48\n",
      "150 activation_43\n",
      "151 activation_48\n",
      "152 average_pooling2d_5\n",
      "153 conv2d_41\n",
      "154 conv2d_44\n",
      "155 conv2d_49\n",
      "156 conv2d_50\n",
      "157 batch_normalization_41\n",
      "158 batch_normalization_44\n",
      "159 batch_normalization_49\n",
      "160 batch_normalization_50\n",
      "161 activation_41\n",
      "162 activation_44\n",
      "163 activation_49\n",
      "164 activation_50\n",
      "165 mixed5\n",
      "166 conv2d_55\n",
      "167 batch_normalization_55\n",
      "168 activation_55\n",
      "169 conv2d_56\n",
      "170 batch_normalization_56\n",
      "171 activation_56\n",
      "172 conv2d_52\n",
      "173 conv2d_57\n",
      "174 batch_normalization_52\n",
      "175 batch_normalization_57\n",
      "176 activation_52\n",
      "177 activation_57\n",
      "178 conv2d_53\n",
      "179 conv2d_58\n",
      "180 batch_normalization_53\n",
      "181 batch_normalization_58\n",
      "182 activation_53\n",
      "183 activation_58\n",
      "184 average_pooling2d_6\n",
      "185 conv2d_51\n",
      "186 conv2d_54\n",
      "187 conv2d_59\n",
      "188 conv2d_60\n",
      "189 batch_normalization_51\n",
      "190 batch_normalization_54\n",
      "191 batch_normalization_59\n",
      "192 batch_normalization_60\n",
      "193 activation_51\n",
      "194 activation_54\n",
      "195 activation_59\n",
      "196 activation_60\n",
      "197 mixed6\n",
      "198 conv2d_65\n",
      "199 batch_normalization_65\n",
      "200 activation_65\n",
      "201 conv2d_66\n",
      "202 batch_normalization_66\n",
      "203 activation_66\n",
      "204 conv2d_62\n",
      "205 conv2d_67\n",
      "206 batch_normalization_62\n",
      "207 batch_normalization_67\n",
      "208 activation_62\n",
      "209 activation_67\n",
      "210 conv2d_63\n",
      "211 conv2d_68\n",
      "212 batch_normalization_63\n",
      "213 batch_normalization_68\n",
      "214 activation_63\n",
      "215 activation_68\n",
      "216 average_pooling2d_7\n",
      "217 conv2d_61\n",
      "218 conv2d_64\n",
      "219 conv2d_69\n",
      "220 conv2d_70\n",
      "221 batch_normalization_61\n",
      "222 batch_normalization_64\n",
      "223 batch_normalization_69\n",
      "224 batch_normalization_70\n",
      "225 activation_61\n",
      "226 activation_64\n",
      "227 activation_69\n",
      "228 activation_70\n",
      "229 mixed7\n",
      "230 conv2d_73\n",
      "231 batch_normalization_73\n",
      "232 activation_73\n",
      "233 conv2d_74\n",
      "234 batch_normalization_74\n",
      "235 activation_74\n",
      "236 conv2d_71\n",
      "237 conv2d_75\n",
      "238 batch_normalization_71\n",
      "239 batch_normalization_75\n",
      "240 activation_71\n",
      "241 activation_75\n",
      "242 conv2d_72\n",
      "243 conv2d_76\n",
      "244 batch_normalization_72\n",
      "245 batch_normalization_76\n",
      "246 activation_72\n",
      "247 activation_76\n",
      "248 max_pooling2d_4\n",
      "249 mixed8\n",
      "250 conv2d_81\n",
      "251 batch_normalization_81\n",
      "252 activation_81\n",
      "253 conv2d_78\n",
      "254 conv2d_82\n",
      "255 batch_normalization_78\n",
      "256 batch_normalization_82\n",
      "257 activation_78\n",
      "258 activation_82\n",
      "259 conv2d_79\n",
      "260 conv2d_80\n",
      "261 conv2d_83\n",
      "262 conv2d_84\n",
      "263 average_pooling2d_8\n",
      "264 conv2d_77\n",
      "265 batch_normalization_79\n",
      "266 batch_normalization_80\n",
      "267 batch_normalization_83\n",
      "268 batch_normalization_84\n",
      "269 conv2d_85\n",
      "270 batch_normalization_77\n",
      "271 activation_79\n",
      "272 activation_80\n",
      "273 activation_83\n",
      "274 activation_84\n",
      "275 batch_normalization_85\n",
      "276 activation_77\n",
      "277 mixed9_0\n",
      "278 concatenate_1\n",
      "279 activation_85\n",
      "280 mixed9\n",
      "281 conv2d_90\n",
      "282 batch_normalization_90\n",
      "283 activation_90\n",
      "284 conv2d_87\n",
      "285 conv2d_91\n",
      "286 batch_normalization_87\n",
      "287 batch_normalization_91\n",
      "288 activation_87\n",
      "289 activation_91\n",
      "290 conv2d_88\n",
      "291 conv2d_89\n",
      "292 conv2d_92\n",
      "293 conv2d_93\n",
      "294 average_pooling2d_9\n",
      "295 conv2d_86\n",
      "296 batch_normalization_88\n",
      "297 batch_normalization_89\n",
      "298 batch_normalization_92\n",
      "299 batch_normalization_93\n",
      "300 conv2d_94\n",
      "301 batch_normalization_86\n",
      "302 activation_88\n",
      "303 activation_89\n",
      "304 activation_92\n",
      "305 activation_93\n",
      "306 batch_normalization_94\n",
      "307 activation_86\n",
      "308 mixed9_1\n",
      "309 concatenate_2\n",
      "310 activation_94\n",
      "311 mixed10\n",
      "312 global_average_pooling2d_1\n",
      "313 dropout_1\n",
      "314 dense_1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    print(i,model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 42s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('inceptionv3_weights_1.h5')  \n",
    "y_pred = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, fname in enumerate(test_file):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('inceptionv3_predict_1.csv', index=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在kaggle上的得分是0.05805"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型二\n",
    "fine-tuning 锁前161层，放开161层之后的层参与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "for layer in model.layers[161:]:\n",
    "    layer.trainable = True\n",
    "model.load_weights('inceptionv3_weights_1.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19969 samples, validate on 4993 samples\n",
      "Epoch 1/5\n",
      "19969/19969 [==============================] - 120s 6ms/step - loss: 0.0741 - acc: 0.9746 - val_loss: 0.0509 - val_acc: 0.9880\n",
      "Epoch 2/5\n",
      "19969/19969 [==============================] - 111s 6ms/step - loss: 0.0263 - acc: 0.9911 - val_loss: 0.0456 - val_acc: 0.9874\n",
      "Epoch 3/5\n",
      "19969/19969 [==============================] - 111s 6ms/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0487 - val_acc: 0.9872\n",
      "Epoch 4/5\n",
      "19969/19969 [==============================] - 111s 6ms/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0472 - val_acc: 0.9864\n",
      "Epoch 5/5\n",
      "19969/19969 [==============================] - 111s 6ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0346 - val_acc: 0.9914\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))\n",
    "model.save_weights('inceptionv3_weights_2.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 43s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, fname in enumerate(test_file):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('inceptionv3_predict_2.csv', index=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在kaggle上的得分是0.05087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型三\n",
    "fine-tuning 锁前252层，放开252层之后的层参与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "for layer in model.layers[252:]:\n",
    "    layer.trainable = True\n",
    "model.load_weights('inceptionv3_weights_2.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19969 samples, validate on 4993 samples\n",
      "Epoch 1/5\n",
      "19969/19969 [==============================] - 94s 5ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0313 - val_acc: 0.9924\n",
      "Epoch 2/5\n",
      "19969/19969 [==============================] - 89s 4ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0333 - val_acc: 0.9926\n",
      "Epoch 3/5\n",
      "19969/19969 [==============================] - 89s 4ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0335 - val_acc: 0.9922\n",
      "Epoch 4/5\n",
      "19969/19969 [==============================] - 89s 4ms/step - loss: 5.1250e-04 - acc: 0.9999 - val_loss: 0.0339 - val_acc: 0.9924\n",
      "Epoch 5/5\n",
      "19969/19969 [==============================] - 89s 4ms/step - loss: 8.3346e-04 - acc: 0.9997 - val_loss: 0.0348 - val_acc: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bf855cfd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 43s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, fname in enumerate(test_file):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('inceptionv3_predict_3.csv', index=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('inceptionv3_weights_3.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在kaggle上的得分是0.04785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
