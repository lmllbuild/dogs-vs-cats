{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2上的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "读取训练和测试图片，格式化成（299,299,3）的格式。并且划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "n = 24962\n",
    "X = np.zeros((n, 299, 299, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, 1), dtype=np.uint8)\n",
    "\n",
    "train_cat2 = os.listdir(\"train2/cat\")\n",
    "train_dog2 = os.listdir(\"train2/dog\")\n",
    "\n",
    "i = 0\n",
    "for filename in train_cat2:\n",
    "    X[i] = cv2.resize(cv2.imread('train/%s' % filename), (299, 299))\n",
    "    y[i] = 0\n",
    "    i += 1\n",
    "for filename in train_dog2:\n",
    "    X[i] = cv2.resize(cv2.imread('train/%s' % filename), (299, 299))\n",
    "    y[i] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 12500\n",
    "X_test = np.zeros((m, 299, 299, 3), dtype=np.uint8)\n",
    "\n",
    "test_file = os.listdir(\"test\")\n",
    "j = 0\n",
    "for filename in test_file:\n",
    "    X_test[j] = cv2.resize(cv2.imread('test/%s' % filename), (299, 299))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 24962\n",
      "X_test size: (12500, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"i=\", i)\n",
    "print(\"X_test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型一\n",
    "去除顶层，锁定其他所有层，不参与训练；在这模型的基础上，加上GAP层和Dropout层，加sigmoid激活函数得出二分类的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionResNetV2(input_tensor=Lambda(inception_resnet_v2.preprocess_input)(Input((299, 299, 3))), weights='imagenet', include_top=False)\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19969 samples, validate on 4993 samples\n",
      "Epoch 1/5\n",
      "19969/19969 [==============================] - 151s 8ms/step - loss: 0.1612 - acc: 0.9441 - val_loss: 0.0646 - val_acc: 0.9806\n",
      "Epoch 2/5\n",
      "19969/19969 [==============================] - 138s 7ms/step - loss: 0.0967 - acc: 0.9651 - val_loss: 0.0667 - val_acc: 0.9790\n",
      "Epoch 3/5\n",
      "19969/19969 [==============================] - 138s 7ms/step - loss: 0.0920 - acc: 0.9670 - val_loss: 0.0533 - val_acc: 0.9828\n",
      "Epoch 4/5\n",
      "19969/19969 [==============================] - 138s 7ms/step - loss: 0.0849 - acc: 0.9684 - val_loss: 0.0936 - val_acc: 0.9692\n",
      "Epoch 5/5\n",
      "19969/19969 [==============================] - 138s 7ms/step - loss: 0.0850 - acc: 0.9703 - val_loss: 0.0545 - val_acc: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d26754fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 lambda_2\n",
      "2 conv2d_315\n",
      "3 batch_normalization_315\n",
      "4 activation_314\n",
      "5 conv2d_316\n",
      "6 batch_normalization_316\n",
      "7 activation_315\n",
      "8 conv2d_317\n",
      "9 batch_normalization_317\n",
      "10 activation_316\n",
      "11 max_pooling2d_8\n",
      "12 conv2d_318\n",
      "13 batch_normalization_318\n",
      "14 activation_317\n",
      "15 conv2d_319\n",
      "16 batch_normalization_319\n",
      "17 activation_318\n",
      "18 max_pooling2d_9\n",
      "19 conv2d_323\n",
      "20 batch_normalization_323\n",
      "21 activation_322\n",
      "22 conv2d_321\n",
      "23 conv2d_324\n",
      "24 batch_normalization_321\n",
      "25 batch_normalization_324\n",
      "26 activation_320\n",
      "27 activation_323\n",
      "28 average_pooling2d_3\n",
      "29 conv2d_320\n",
      "30 conv2d_322\n",
      "31 conv2d_325\n",
      "32 conv2d_326\n",
      "33 batch_normalization_320\n",
      "34 batch_normalization_322\n",
      "35 batch_normalization_325\n",
      "36 batch_normalization_326\n",
      "37 activation_319\n",
      "38 activation_321\n",
      "39 activation_324\n",
      "40 activation_325\n",
      "41 mixed_5b\n",
      "42 conv2d_330\n",
      "43 batch_normalization_330\n",
      "44 activation_329\n",
      "45 conv2d_328\n",
      "46 conv2d_331\n",
      "47 batch_normalization_328\n",
      "48 batch_normalization_331\n",
      "49 activation_327\n",
      "50 activation_330\n",
      "51 conv2d_327\n",
      "52 conv2d_329\n",
      "53 conv2d_332\n",
      "54 batch_normalization_327\n",
      "55 batch_normalization_329\n",
      "56 batch_normalization_332\n",
      "57 activation_326\n",
      "58 activation_328\n",
      "59 activation_331\n",
      "60 block35_1_mixed\n",
      "61 block35_1_conv\n",
      "62 block35_1\n",
      "63 block35_1_ac\n",
      "64 conv2d_336\n",
      "65 batch_normalization_336\n",
      "66 activation_335\n",
      "67 conv2d_334\n",
      "68 conv2d_337\n",
      "69 batch_normalization_334\n",
      "70 batch_normalization_337\n",
      "71 activation_333\n",
      "72 activation_336\n",
      "73 conv2d_333\n",
      "74 conv2d_335\n",
      "75 conv2d_338\n",
      "76 batch_normalization_333\n",
      "77 batch_normalization_335\n",
      "78 batch_normalization_338\n",
      "79 activation_332\n",
      "80 activation_334\n",
      "81 activation_337\n",
      "82 block35_2_mixed\n",
      "83 block35_2_conv\n",
      "84 block35_2\n",
      "85 block35_2_ac\n",
      "86 conv2d_342\n",
      "87 batch_normalization_342\n",
      "88 activation_341\n",
      "89 conv2d_340\n",
      "90 conv2d_343\n",
      "91 batch_normalization_340\n",
      "92 batch_normalization_343\n",
      "93 activation_339\n",
      "94 activation_342\n",
      "95 conv2d_339\n",
      "96 conv2d_341\n",
      "97 conv2d_344\n",
      "98 batch_normalization_339\n",
      "99 batch_normalization_341\n",
      "100 batch_normalization_344\n",
      "101 activation_338\n",
      "102 activation_340\n",
      "103 activation_343\n",
      "104 block35_3_mixed\n",
      "105 block35_3_conv\n",
      "106 block35_3\n",
      "107 block35_3_ac\n",
      "108 conv2d_348\n",
      "109 batch_normalization_348\n",
      "110 activation_347\n",
      "111 conv2d_346\n",
      "112 conv2d_349\n",
      "113 batch_normalization_346\n",
      "114 batch_normalization_349\n",
      "115 activation_345\n",
      "116 activation_348\n",
      "117 conv2d_345\n",
      "118 conv2d_347\n",
      "119 conv2d_350\n",
      "120 batch_normalization_345\n",
      "121 batch_normalization_347\n",
      "122 batch_normalization_350\n",
      "123 activation_344\n",
      "124 activation_346\n",
      "125 activation_349\n",
      "126 block35_4_mixed\n",
      "127 block35_4_conv\n",
      "128 block35_4\n",
      "129 block35_4_ac\n",
      "130 conv2d_354\n",
      "131 batch_normalization_354\n",
      "132 activation_353\n",
      "133 conv2d_352\n",
      "134 conv2d_355\n",
      "135 batch_normalization_352\n",
      "136 batch_normalization_355\n",
      "137 activation_351\n",
      "138 activation_354\n",
      "139 conv2d_351\n",
      "140 conv2d_353\n",
      "141 conv2d_356\n",
      "142 batch_normalization_351\n",
      "143 batch_normalization_353\n",
      "144 batch_normalization_356\n",
      "145 activation_350\n",
      "146 activation_352\n",
      "147 activation_355\n",
      "148 block35_5_mixed\n",
      "149 block35_5_conv\n",
      "150 block35_5\n",
      "151 block35_5_ac\n",
      "152 conv2d_360\n",
      "153 batch_normalization_360\n",
      "154 activation_359\n",
      "155 conv2d_358\n",
      "156 conv2d_361\n",
      "157 batch_normalization_358\n",
      "158 batch_normalization_361\n",
      "159 activation_357\n",
      "160 activation_360\n",
      "161 conv2d_357\n",
      "162 conv2d_359\n",
      "163 conv2d_362\n",
      "164 batch_normalization_357\n",
      "165 batch_normalization_359\n",
      "166 batch_normalization_362\n",
      "167 activation_356\n",
      "168 activation_358\n",
      "169 activation_361\n",
      "170 block35_6_mixed\n",
      "171 block35_6_conv\n",
      "172 block35_6\n",
      "173 block35_6_ac\n",
      "174 conv2d_366\n",
      "175 batch_normalization_366\n",
      "176 activation_365\n",
      "177 conv2d_364\n",
      "178 conv2d_367\n",
      "179 batch_normalization_364\n",
      "180 batch_normalization_367\n",
      "181 activation_363\n",
      "182 activation_366\n",
      "183 conv2d_363\n",
      "184 conv2d_365\n",
      "185 conv2d_368\n",
      "186 batch_normalization_363\n",
      "187 batch_normalization_365\n",
      "188 batch_normalization_368\n",
      "189 activation_362\n",
      "190 activation_364\n",
      "191 activation_367\n",
      "192 block35_7_mixed\n",
      "193 block35_7_conv\n",
      "194 block35_7\n",
      "195 block35_7_ac\n",
      "196 conv2d_372\n",
      "197 batch_normalization_372\n",
      "198 activation_371\n",
      "199 conv2d_370\n",
      "200 conv2d_373\n",
      "201 batch_normalization_370\n",
      "202 batch_normalization_373\n",
      "203 activation_369\n",
      "204 activation_372\n",
      "205 conv2d_369\n",
      "206 conv2d_371\n",
      "207 conv2d_374\n",
      "208 batch_normalization_369\n",
      "209 batch_normalization_371\n",
      "210 batch_normalization_374\n",
      "211 activation_368\n",
      "212 activation_370\n",
      "213 activation_373\n",
      "214 block35_8_mixed\n",
      "215 block35_8_conv\n",
      "216 block35_8\n",
      "217 block35_8_ac\n",
      "218 conv2d_378\n",
      "219 batch_normalization_378\n",
      "220 activation_377\n",
      "221 conv2d_376\n",
      "222 conv2d_379\n",
      "223 batch_normalization_376\n",
      "224 batch_normalization_379\n",
      "225 activation_375\n",
      "226 activation_378\n",
      "227 conv2d_375\n",
      "228 conv2d_377\n",
      "229 conv2d_380\n",
      "230 batch_normalization_375\n",
      "231 batch_normalization_377\n",
      "232 batch_normalization_380\n",
      "233 activation_374\n",
      "234 activation_376\n",
      "235 activation_379\n",
      "236 block35_9_mixed\n",
      "237 block35_9_conv\n",
      "238 block35_9\n",
      "239 block35_9_ac\n",
      "240 conv2d_384\n",
      "241 batch_normalization_384\n",
      "242 activation_383\n",
      "243 conv2d_382\n",
      "244 conv2d_385\n",
      "245 batch_normalization_382\n",
      "246 batch_normalization_385\n",
      "247 activation_381\n",
      "248 activation_384\n",
      "249 conv2d_381\n",
      "250 conv2d_383\n",
      "251 conv2d_386\n",
      "252 batch_normalization_381\n",
      "253 batch_normalization_383\n",
      "254 batch_normalization_386\n",
      "255 activation_380\n",
      "256 activation_382\n",
      "257 activation_385\n",
      "258 block35_10_mixed\n",
      "259 block35_10_conv\n",
      "260 block35_10\n",
      "261 block35_10_ac\n",
      "262 conv2d_388\n",
      "263 batch_normalization_388\n",
      "264 activation_387\n",
      "265 conv2d_389\n",
      "266 batch_normalization_389\n",
      "267 activation_388\n",
      "268 conv2d_387\n",
      "269 conv2d_390\n",
      "270 batch_normalization_387\n",
      "271 batch_normalization_390\n",
      "272 activation_386\n",
      "273 activation_389\n",
      "274 max_pooling2d_10\n",
      "275 mixed_6a\n",
      "276 conv2d_392\n",
      "277 batch_normalization_392\n",
      "278 activation_391\n",
      "279 conv2d_393\n",
      "280 batch_normalization_393\n",
      "281 activation_392\n",
      "282 conv2d_391\n",
      "283 conv2d_394\n",
      "284 batch_normalization_391\n",
      "285 batch_normalization_394\n",
      "286 activation_390\n",
      "287 activation_393\n",
      "288 block17_1_mixed\n",
      "289 block17_1_conv\n",
      "290 block17_1\n",
      "291 block17_1_ac\n",
      "292 conv2d_396\n",
      "293 batch_normalization_396\n",
      "294 activation_395\n",
      "295 conv2d_397\n",
      "296 batch_normalization_397\n",
      "297 activation_396\n",
      "298 conv2d_395\n",
      "299 conv2d_398\n",
      "300 batch_normalization_395\n",
      "301 batch_normalization_398\n",
      "302 activation_394\n",
      "303 activation_397\n",
      "304 block17_2_mixed\n",
      "305 block17_2_conv\n",
      "306 block17_2\n",
      "307 block17_2_ac\n",
      "308 conv2d_400\n",
      "309 batch_normalization_400\n",
      "310 activation_399\n",
      "311 conv2d_401\n",
      "312 batch_normalization_401\n",
      "313 activation_400\n",
      "314 conv2d_399\n",
      "315 conv2d_402\n",
      "316 batch_normalization_399\n",
      "317 batch_normalization_402\n",
      "318 activation_398\n",
      "319 activation_401\n",
      "320 block17_3_mixed\n",
      "321 block17_3_conv\n",
      "322 block17_3\n",
      "323 block17_3_ac\n",
      "324 conv2d_404\n",
      "325 batch_normalization_404\n",
      "326 activation_403\n",
      "327 conv2d_405\n",
      "328 batch_normalization_405\n",
      "329 activation_404\n",
      "330 conv2d_403\n",
      "331 conv2d_406\n",
      "332 batch_normalization_403\n",
      "333 batch_normalization_406\n",
      "334 activation_402\n",
      "335 activation_405\n",
      "336 block17_4_mixed\n",
      "337 block17_4_conv\n",
      "338 block17_4\n",
      "339 block17_4_ac\n",
      "340 conv2d_408\n",
      "341 batch_normalization_408\n",
      "342 activation_407\n",
      "343 conv2d_409\n",
      "344 batch_normalization_409\n",
      "345 activation_408\n",
      "346 conv2d_407\n",
      "347 conv2d_410\n",
      "348 batch_normalization_407\n",
      "349 batch_normalization_410\n",
      "350 activation_406\n",
      "351 activation_409\n",
      "352 block17_5_mixed\n",
      "353 block17_5_conv\n",
      "354 block17_5\n",
      "355 block17_5_ac\n",
      "356 conv2d_412\n",
      "357 batch_normalization_412\n",
      "358 activation_411\n",
      "359 conv2d_413\n",
      "360 batch_normalization_413\n",
      "361 activation_412\n",
      "362 conv2d_411\n",
      "363 conv2d_414\n",
      "364 batch_normalization_411\n",
      "365 batch_normalization_414\n",
      "366 activation_410\n",
      "367 activation_413\n",
      "368 block17_6_mixed\n",
      "369 block17_6_conv\n",
      "370 block17_6\n",
      "371 block17_6_ac\n",
      "372 conv2d_416\n",
      "373 batch_normalization_416\n",
      "374 activation_415\n",
      "375 conv2d_417\n",
      "376 batch_normalization_417\n",
      "377 activation_416\n",
      "378 conv2d_415\n",
      "379 conv2d_418\n",
      "380 batch_normalization_415\n",
      "381 batch_normalization_418\n",
      "382 activation_414\n",
      "383 activation_417\n",
      "384 block17_7_mixed\n",
      "385 block17_7_conv\n",
      "386 block17_7\n",
      "387 block17_7_ac\n",
      "388 conv2d_420\n",
      "389 batch_normalization_420\n",
      "390 activation_419\n",
      "391 conv2d_421\n",
      "392 batch_normalization_421\n",
      "393 activation_420\n",
      "394 conv2d_419\n",
      "395 conv2d_422\n",
      "396 batch_normalization_419\n",
      "397 batch_normalization_422\n",
      "398 activation_418\n",
      "399 activation_421\n",
      "400 block17_8_mixed\n",
      "401 block17_8_conv\n",
      "402 block17_8\n",
      "403 block17_8_ac\n",
      "404 conv2d_424\n",
      "405 batch_normalization_424\n",
      "406 activation_423\n",
      "407 conv2d_425\n",
      "408 batch_normalization_425\n",
      "409 activation_424\n",
      "410 conv2d_423\n",
      "411 conv2d_426\n",
      "412 batch_normalization_423\n",
      "413 batch_normalization_426\n",
      "414 activation_422\n",
      "415 activation_425\n",
      "416 block17_9_mixed\n",
      "417 block17_9_conv\n",
      "418 block17_9\n",
      "419 block17_9_ac\n",
      "420 conv2d_428\n",
      "421 batch_normalization_428\n",
      "422 activation_427\n",
      "423 conv2d_429\n",
      "424 batch_normalization_429\n",
      "425 activation_428\n",
      "426 conv2d_427\n",
      "427 conv2d_430\n",
      "428 batch_normalization_427\n",
      "429 batch_normalization_430\n",
      "430 activation_426\n",
      "431 activation_429\n",
      "432 block17_10_mixed\n",
      "433 block17_10_conv\n",
      "434 block17_10\n",
      "435 block17_10_ac\n",
      "436 conv2d_432\n",
      "437 batch_normalization_432\n",
      "438 activation_431\n",
      "439 conv2d_433\n",
      "440 batch_normalization_433\n",
      "441 activation_432\n",
      "442 conv2d_431\n",
      "443 conv2d_434\n",
      "444 batch_normalization_431\n",
      "445 batch_normalization_434\n",
      "446 activation_430\n",
      "447 activation_433\n",
      "448 block17_11_mixed\n",
      "449 block17_11_conv\n",
      "450 block17_11\n",
      "451 block17_11_ac\n",
      "452 conv2d_436\n",
      "453 batch_normalization_436\n",
      "454 activation_435\n",
      "455 conv2d_437\n",
      "456 batch_normalization_437\n",
      "457 activation_436\n",
      "458 conv2d_435\n",
      "459 conv2d_438\n",
      "460 batch_normalization_435\n",
      "461 batch_normalization_438\n",
      "462 activation_434\n",
      "463 activation_437\n",
      "464 block17_12_mixed\n",
      "465 block17_12_conv\n",
      "466 block17_12\n",
      "467 block17_12_ac\n",
      "468 conv2d_440\n",
      "469 batch_normalization_440\n",
      "470 activation_439\n",
      "471 conv2d_441\n",
      "472 batch_normalization_441\n",
      "473 activation_440\n",
      "474 conv2d_439\n",
      "475 conv2d_442\n",
      "476 batch_normalization_439\n",
      "477 batch_normalization_442\n",
      "478 activation_438\n",
      "479 activation_441\n",
      "480 block17_13_mixed\n",
      "481 block17_13_conv\n",
      "482 block17_13\n",
      "483 block17_13_ac\n",
      "484 conv2d_444\n",
      "485 batch_normalization_444\n",
      "486 activation_443\n",
      "487 conv2d_445\n",
      "488 batch_normalization_445\n",
      "489 activation_444\n",
      "490 conv2d_443\n",
      "491 conv2d_446\n",
      "492 batch_normalization_443\n",
      "493 batch_normalization_446\n",
      "494 activation_442\n",
      "495 activation_445\n",
      "496 block17_14_mixed\n",
      "497 block17_14_conv\n",
      "498 block17_14\n",
      "499 block17_14_ac\n",
      "500 conv2d_448\n",
      "501 batch_normalization_448\n",
      "502 activation_447\n",
      "503 conv2d_449\n",
      "504 batch_normalization_449\n",
      "505 activation_448\n",
      "506 conv2d_447\n",
      "507 conv2d_450\n",
      "508 batch_normalization_447\n",
      "509 batch_normalization_450\n",
      "510 activation_446\n",
      "511 activation_449\n",
      "512 block17_15_mixed\n",
      "513 block17_15_conv\n",
      "514 block17_15\n",
      "515 block17_15_ac\n",
      "516 conv2d_452\n",
      "517 batch_normalization_452\n",
      "518 activation_451\n",
      "519 conv2d_453\n",
      "520 batch_normalization_453\n",
      "521 activation_452\n",
      "522 conv2d_451\n",
      "523 conv2d_454\n",
      "524 batch_normalization_451\n",
      "525 batch_normalization_454\n",
      "526 activation_450\n",
      "527 activation_453\n",
      "528 block17_16_mixed\n",
      "529 block17_16_conv\n",
      "530 block17_16\n",
      "531 block17_16_ac\n",
      "532 conv2d_456\n",
      "533 batch_normalization_456\n",
      "534 activation_455\n",
      "535 conv2d_457\n",
      "536 batch_normalization_457\n",
      "537 activation_456\n",
      "538 conv2d_455\n",
      "539 conv2d_458\n",
      "540 batch_normalization_455\n",
      "541 batch_normalization_458\n",
      "542 activation_454\n",
      "543 activation_457\n",
      "544 block17_17_mixed\n",
      "545 block17_17_conv\n",
      "546 block17_17\n",
      "547 block17_17_ac\n",
      "548 conv2d_460\n",
      "549 batch_normalization_460\n",
      "550 activation_459\n",
      "551 conv2d_461\n",
      "552 batch_normalization_461\n",
      "553 activation_460\n",
      "554 conv2d_459\n",
      "555 conv2d_462\n",
      "556 batch_normalization_459\n",
      "557 batch_normalization_462\n",
      "558 activation_458\n",
      "559 activation_461\n",
      "560 block17_18_mixed\n",
      "561 block17_18_conv\n",
      "562 block17_18\n",
      "563 block17_18_ac\n",
      "564 conv2d_464\n",
      "565 batch_normalization_464\n",
      "566 activation_463\n",
      "567 conv2d_465\n",
      "568 batch_normalization_465\n",
      "569 activation_464\n",
      "570 conv2d_463\n",
      "571 conv2d_466\n",
      "572 batch_normalization_463\n",
      "573 batch_normalization_466\n",
      "574 activation_462\n",
      "575 activation_465\n",
      "576 block17_19_mixed\n",
      "577 block17_19_conv\n",
      "578 block17_19\n",
      "579 block17_19_ac\n",
      "580 conv2d_468\n",
      "581 batch_normalization_468\n",
      "582 activation_467\n",
      "583 conv2d_469\n",
      "584 batch_normalization_469\n",
      "585 activation_468\n",
      "586 conv2d_467\n",
      "587 conv2d_470\n",
      "588 batch_normalization_467\n",
      "589 batch_normalization_470\n",
      "590 activation_466\n",
      "591 activation_469\n",
      "592 block17_20_mixed\n",
      "593 block17_20_conv\n",
      "594 block17_20\n",
      "595 block17_20_ac\n",
      "596 conv2d_475\n",
      "597 batch_normalization_475\n",
      "598 activation_474\n",
      "599 conv2d_471\n",
      "600 conv2d_473\n",
      "601 conv2d_476\n",
      "602 batch_normalization_471\n",
      "603 batch_normalization_473\n",
      "604 batch_normalization_476\n",
      "605 activation_470\n",
      "606 activation_472\n",
      "607 activation_475\n",
      "608 conv2d_472\n",
      "609 conv2d_474\n",
      "610 conv2d_477\n",
      "611 batch_normalization_472\n",
      "612 batch_normalization_474\n",
      "613 batch_normalization_477\n",
      "614 activation_471\n",
      "615 activation_473\n",
      "616 activation_476\n",
      "617 max_pooling2d_11\n",
      "618 mixed_7a\n",
      "619 conv2d_479\n",
      "620 batch_normalization_479\n",
      "621 activation_478\n",
      "622 conv2d_480\n",
      "623 batch_normalization_480\n",
      "624 activation_479\n",
      "625 conv2d_478\n",
      "626 conv2d_481\n",
      "627 batch_normalization_478\n",
      "628 batch_normalization_481\n",
      "629 activation_477\n",
      "630 activation_480\n",
      "631 block8_1_mixed\n",
      "632 block8_1_conv\n",
      "633 block8_1\n",
      "634 block8_1_ac\n",
      "635 conv2d_483\n",
      "636 batch_normalization_483\n",
      "637 activation_482\n",
      "638 conv2d_484\n",
      "639 batch_normalization_484\n",
      "640 activation_483\n",
      "641 conv2d_482\n",
      "642 conv2d_485\n",
      "643 batch_normalization_482\n",
      "644 batch_normalization_485\n",
      "645 activation_481\n",
      "646 activation_484\n",
      "647 block8_2_mixed\n",
      "648 block8_2_conv\n",
      "649 block8_2\n",
      "650 block8_2_ac\n",
      "651 conv2d_487\n",
      "652 batch_normalization_487\n",
      "653 activation_486\n",
      "654 conv2d_488\n",
      "655 batch_normalization_488\n",
      "656 activation_487\n",
      "657 conv2d_486\n",
      "658 conv2d_489\n",
      "659 batch_normalization_486\n",
      "660 batch_normalization_489\n",
      "661 activation_485\n",
      "662 activation_488\n",
      "663 block8_3_mixed\n",
      "664 block8_3_conv\n",
      "665 block8_3\n",
      "666 block8_3_ac\n",
      "667 conv2d_491\n",
      "668 batch_normalization_491\n",
      "669 activation_490\n",
      "670 conv2d_492\n",
      "671 batch_normalization_492\n",
      "672 activation_491\n",
      "673 conv2d_490\n",
      "674 conv2d_493\n",
      "675 batch_normalization_490\n",
      "676 batch_normalization_493\n",
      "677 activation_489\n",
      "678 activation_492\n",
      "679 block8_4_mixed\n",
      "680 block8_4_conv\n",
      "681 block8_4\n",
      "682 block8_4_ac\n",
      "683 conv2d_495\n",
      "684 batch_normalization_495\n",
      "685 activation_494\n",
      "686 conv2d_496\n",
      "687 batch_normalization_496\n",
      "688 activation_495\n",
      "689 conv2d_494\n",
      "690 conv2d_497\n",
      "691 batch_normalization_494\n",
      "692 batch_normalization_497\n",
      "693 activation_493\n",
      "694 activation_496\n",
      "695 block8_5_mixed\n",
      "696 block8_5_conv\n",
      "697 block8_5\n",
      "698 block8_5_ac\n",
      "699 conv2d_499\n",
      "700 batch_normalization_499\n",
      "701 activation_498\n",
      "702 conv2d_500\n",
      "703 batch_normalization_500\n",
      "704 activation_499\n",
      "705 conv2d_498\n",
      "706 conv2d_501\n",
      "707 batch_normalization_498\n",
      "708 batch_normalization_501\n",
      "709 activation_497\n",
      "710 activation_500\n",
      "711 block8_6_mixed\n",
      "712 block8_6_conv\n",
      "713 block8_6\n",
      "714 block8_6_ac\n",
      "715 conv2d_503\n",
      "716 batch_normalization_503\n",
      "717 activation_502\n",
      "718 conv2d_504\n",
      "719 batch_normalization_504\n",
      "720 activation_503\n",
      "721 conv2d_502\n",
      "722 conv2d_505\n",
      "723 batch_normalization_502\n",
      "724 batch_normalization_505\n",
      "725 activation_501\n",
      "726 activation_504\n",
      "727 block8_7_mixed\n",
      "728 block8_7_conv\n",
      "729 block8_7\n",
      "730 block8_7_ac\n",
      "731 conv2d_507\n",
      "732 batch_normalization_507\n",
      "733 activation_506\n",
      "734 conv2d_508\n",
      "735 batch_normalization_508\n",
      "736 activation_507\n",
      "737 conv2d_506\n",
      "738 conv2d_509\n",
      "739 batch_normalization_506\n",
      "740 batch_normalization_509\n",
      "741 activation_505\n",
      "742 activation_508\n",
      "743 block8_8_mixed\n",
      "744 block8_8_conv\n",
      "745 block8_8\n",
      "746 block8_8_ac\n",
      "747 conv2d_511\n",
      "748 batch_normalization_511\n",
      "749 activation_510\n",
      "750 conv2d_512\n",
      "751 batch_normalization_512\n",
      "752 activation_511\n",
      "753 conv2d_510\n",
      "754 conv2d_513\n",
      "755 batch_normalization_510\n",
      "756 batch_normalization_513\n",
      "757 activation_509\n",
      "758 activation_512\n",
      "759 block8_9_mixed\n",
      "760 block8_9_conv\n",
      "761 block8_9\n",
      "762 block8_9_ac\n",
      "763 conv2d_515\n",
      "764 batch_normalization_515\n",
      "765 activation_514\n",
      "766 conv2d_516\n",
      "767 batch_normalization_516\n",
      "768 activation_515\n",
      "769 conv2d_514\n",
      "770 conv2d_517\n",
      "771 batch_normalization_514\n",
      "772 batch_normalization_517\n",
      "773 activation_513\n",
      "774 activation_516\n",
      "775 block8_10_mixed\n",
      "776 block8_10_conv\n",
      "777 block8_10\n",
      "778 conv_7b\n",
      "779 conv_7b_bn\n",
      "780 conv_7b_ac\n",
      "781 global_average_pooling2d_2\n",
      "782 dropout_2\n",
      "783 dense_2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    print(i,model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 78s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('inceptionresnetv2_weights_1.h5')  \n",
    "y_pred = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.991332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     label\n",
       "0   1  0.995000\n",
       "1   2  0.991332"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, fname in enumerate(test_file):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('inceptionresnetv2_predict_1.csv', index=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在kaggle上得分是0.07994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型二\n",
    "fine-tuning 锁前605层，放开605层之后的层参与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "for layer in model.layers[605:]:\n",
    "    layer.trainable = True\n",
    "model.load_weights('inceptionresnetv2_weights_1.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19969 samples, validate on 4993 samples\n",
      "Epoch 1/5\n",
      "19969/19969 [==============================] - 182s 9ms/step - loss: 0.0527 - acc: 0.9811 - val_loss: 0.0655 - val_acc: 0.9888\n",
      "Epoch 2/5\n",
      "19969/19969 [==============================] - 163s 8ms/step - loss: 0.0195 - acc: 0.9922 - val_loss: 0.0091 - val_acc: 0.9964\n",
      "Epoch 3/5\n",
      "19969/19969 [==============================] - 163s 8ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 4/5\n",
      "19969/19969 [==============================] - 163s 8ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0115 - val_acc: 0.9958\n",
      "Epoch 5/5\n",
      "19969/19969 [==============================] - 163s 8ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))\n",
    "model.save_weights('inceptionresnetv2_weights_2.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 78s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, fname in enumerate(test_file):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('inceptionresnetv2_predict_2.csv', index=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在kaggle上得分是0.04352"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型三\n",
    "fine-tuning 锁前701层，放开701层之后的层参与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "for layer in model.layers[701:]:\n",
    "    layer.trainable = True\n",
    "model.load_weights('inceptionresnetv2_weights_2.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19969 samples, validate on 4993 samples\n",
      "Epoch 1/5\n",
      "19969/19969 [==============================] - 145s 7ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0110 - val_acc: 0.9972\n",
      "Epoch 2/5\n",
      "19969/19969 [==============================] - 128s 6ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0113 - val_acc: 0.9974\n",
      "Epoch 3/5\n",
      "19969/19969 [==============================] - 128s 6ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0121 - val_acc: 0.9970\n",
      "Epoch 4/5\n",
      "19969/19969 [==============================] - 128s 6ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0126 - val_acc: 0.9966\n",
      "Epoch 5/5\n",
      "19969/19969 [==============================] - 128s 6ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0129 - val_acc: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d1af0b860>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 73s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "for i, fname in enumerate(test_file):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('inceptionresnetv2_predict_3.csv', index=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('inceptionresnetv2_weights_3.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在kaggle上得分是0.04522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
